{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">**Extract information from image for Confluence Data**</font>\n",
    "\n",
    "Для данной работы возникло предположение - поскольку chatGPT assistant при загрузке данных по факту построенны на RAG c chunk размером 800 и перекрытием 400, возникло предположение извлекать из отдельных страниц pdf-файлов изображений с целью формирования полных знаний.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Chart 1. Загрузка файлов из директории и выполнение целевого препроцессинга изображения</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import io \n",
    "from PyPDF2 import PdfReader\n",
    "from docx import Document\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "from docx2pdf import convert\n",
    "\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.pdfgen import canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_texts_to_pdf(texts, output_pdf_path):\n",
    "    # Save collected texts to a PDF file\n",
    "    c = canvas.Canvas(output_pdf_path, pagesize=letter)\n",
    "    width, height = letter\n",
    "    y_position = height - 50  # Starting position on the page\n",
    "\n",
    "    for text in texts:\n",
    "        for line in text.split('\\n'):\n",
    "            c.drawString(50, y_position, line)\n",
    "            y_position -= 15  # Move to the next line\n",
    "            if y_position < 50:\n",
    "                c.showPage()\n",
    "                y_position = height - 50\n",
    "    c.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_image_from_file(file, path_dir, processed_dir, image_processing_function=None):\n",
    "    def extract_text_from_doc(file, path_dir, processed_dir, image_processing_function=None):\n",
    "        docx_path = os.path.join(path_dir, file)\n",
    "        pdf_temp_path = os.path.join(processed_dir, file.replace('.docx', '_temp.pdf'))\n",
    "\n",
    "        # Convert DOCX to PDF\n",
    "        convert(docx_path, pdf_temp_path)\n",
    "\n",
    "        # Convert PDF pages to images\n",
    "        images = convert_from_path(pdf_temp_path)\n",
    "\n",
    "        processed_texts = []\n",
    "        for img in images:\n",
    "            if image_processing_function:\n",
    "                text = image_processing_function(img)\n",
    "                processed_texts.append(text)\n",
    "            else:\n",
    "                # If default (image_processing_function=None), we collect empty strings\n",
    "                processed_texts.append('')\n",
    "\n",
    "        # Сreate a PDF from the collected texts\n",
    "        output_pdf_path = os.path.join(processed_dir, file.replace('.docx', '.pdf'))\n",
    "        save_texts_to_pdf(processed_texts, output_pdf_path)\n",
    "\n",
    "        # Delete temp PDF file\n",
    "        os.remove(pdf_temp_path)\n",
    "\n",
    "    def extract_text_from_pdf(file, path_dir, processed_dir, image_processing_function=None):\n",
    "        pdf_path = os.path.join(path_dir, file)\n",
    "        # Convert PDF pages to images\n",
    "        images = convert_from_path(pdf_path)\n",
    "\n",
    "        processed_texts = []\n",
    "        for img in images:\n",
    "            if image_processing_function:\n",
    "                text = image_processing_function(img)\n",
    "                processed_texts.append(text)\n",
    "            else:\n",
    "                processed_texts.append('')\n",
    "\n",
    "        # Сreate a PDF from the collected texts\n",
    "        output_pdf_path = os.path.join(processed_dir, file)\n",
    "        save_texts_to_pdf(processed_texts, output_pdf_path)\n",
    "\n",
    "    file_name = file.lower()\n",
    "    if file_name.endswith('.pdf'):\n",
    "        extract_text_from_pdf(file, path_dir, processed_dir, image_processing_function)\n",
    "    elif file_name.endswith('.docx'):\n",
    "        extract_text_from_doc(file, path_dir, processed_dir, image_processing_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test example function\n",
    "def my_image_processing_function(img):\n",
    "    buffer = io.BytesIO()\n",
    "    img.save(buffer, format='PNG')\n",
    "    img_bytes = buffer.getvalue()\n",
    "    img_str = img_bytes.decode('latin1')  \n",
    "    return img_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_document(path_dir, image_processing_function):\n",
    "    path_files = [f for f in os.listdir(path_dir)]\n",
    "\n",
    "    processed_dir = os.path.join(path_dir, 'processed')\n",
    "\n",
    "    # if not directory, create\n",
    "    if not os.path.exists(processed_dir):\n",
    "        os.makedirs(processed_dir)\n",
    "\n",
    "    # main cycle preprocessing\n",
    "    for file in path_files:\n",
    "        extract_image_from_file(file, path_dir, processed_dir, image_processing_function=image_processing_function)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_document(\"data_confluence\", image_processing_function=my_image_processing_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Chart 2. Взаимодействие с OpenAPI для анализа изображения</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Асинхронная версия**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import base64\n",
    "import logging\n",
    "import io \n",
    "from io import BytesIO\n",
    "import os\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "from pdf2image import convert_from_path\n",
    "from PyPDF2 import PdfReader\n",
    "from docx import Document\n",
    "from PIL import Image\n",
    "from docx2pdf import convert\n",
    "\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.pdfgen import canvas\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s-%(asctime)s - %(message)s')\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reportlab.pdfbase import pdfmetrics\n",
    "from reportlab.pdfbase.ttfonts import TTFont\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.pdfgen import canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_texts_to_pdf(texts, output_pdf_path):\n",
    "    # install font with russian language for to solve encoding issues\n",
    "    pdfmetrics.registerFont(TTFont('DejaVuSans', 'DejaVuSans.ttf'))\n",
    "\n",
    "    # Save collected texts to a PDF file\n",
    "    c = canvas.Canvas(output_pdf_path, pagesize=letter)\n",
    "    c.setFont('DejaVuSans', 12)\n",
    "    width, height = letter\n",
    "    y_position = height - 50  # Starting position on the page\n",
    "\n",
    "    for text in texts:\n",
    "        for line in text.split('\\n'):\n",
    "            c.drawString(50, y_position, line)\n",
    "            y_position -= 15  # Move to the next line\n",
    "            if y_position < 50:\n",
    "                c.showPage()\n",
    "                c.setFont('DejaVuSans', 12)\n",
    "                y_position = height - 50\n",
    "    c.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to encode the image\n",
    "def encode_image(image):\n",
    "    from io import BytesIO\n",
    "    buffered = BytesIO()\n",
    "    image.save(buffered, format=\"JPEG\")  # Сохраняем как JPEG\n",
    "    return base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "  \n",
    "\n",
    "async def image_processing_function(images, semaphore, file_name):\n",
    "    client = ChatOpenAI(\n",
    "        api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "        model=\"gpt-4o-mini\",\n",
    "        max_retries=3,\n",
    "        timeout=None,\n",
    "        max_tokens=None,\n",
    "    )\n",
    "\n",
    "    prompt = \"\"\"\n",
    "<System>\n",
    "You are an assistant for extracting data from images, which are just pages of doc or pdf documents.\n",
    "This is a very important role, and the quality of the data depends entirely on your actions, and therefore the result of all the work. In this case, you are working with the documentation of an internal product based on OpenText.\n",
    "\n",
    "<Instructions>\n",
    "You need to perform the following, but do not mention these steps or the algorithm in your response. Only provide the final extracted data.\n",
    "\n",
    "1. Extract the text from the page that is not linked to any graphic elements. It is very important not to shorten the code.\n",
    "2. Extract data from the graphical elements using the following template:\n",
    "<\n",
    "[Entity_1 (\"Entity_name_1\") -> location1] - functional_description_1 and related_to_other_entities_1\n",
    "[Entity_2 (\"Entity_name_2\") -> location2] - functional_description_2 and related_to_other_entities_2\n",
    "...\n",
    "[Entity_n (\"Entity_name_n\") -> location_n] - functional_description_n\n",
    ">\n",
    "After that, extract brief information by indirectly answering questions like \"What is depicted here?\" and \"What functionality is being performed?\".\n",
    "\n",
    "3. Combine the data obtained in steps 1 and 2.\n",
    "\n",
    "<Final Instruction>\n",
    "Provide only the combined extracted data. Do not include any step numbers, explanations, or descriptions of your process in your response.\n",
    "    \"\"\"\n",
    "\n",
    "    total_requests = len(images)\n",
    "    completed_requests = 0\n",
    "\n",
    "    async def process_image(image_path):\n",
    "        nonlocal completed_requests\n",
    "        async with semaphore:  # Limit concurrency with the semaphore\n",
    "            base64_image = encode_image(image_path)\n",
    "            input_model = [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": prompt},\n",
    "                        {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}}\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "            response = await client.ainvoke(input=input_model, temperature=0.2)\n",
    "            answer = response.content\n",
    "            logging.info(answer)\n",
    "            completed_requests += 1\n",
    "\n",
    "            if completed_requests % 50 == 0 or completed_requests == total_requests:\n",
    "                logging.info(f\"File '{file_name}': complete {completed_requests}/{total_requests} query.\")\n",
    "\n",
    "            return answer\n",
    "\n",
    "    tasks = [process_image(image) for image in images]\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def extract_image_from_file(file, path_dir, processed_dir, image_processing_function=None, semaphore=None):\n",
    "    async def extract_text_from_doc(file, path_dir, processed_dir, image_processing_function=None, semaphore=None):\n",
    "        docx_path = os.path.join(path_dir, file)\n",
    "        pdf_temp_path = os.path.join(processed_dir, file.replace('.docx', '_temp.pdf'))\n",
    "\n",
    "        # Convert DOCX to PDF\n",
    "        convert(docx_path, pdf_temp_path)\n",
    "\n",
    "        # Convert PDF pages to images\n",
    "        images = convert_from_path(pdf_temp_path)\n",
    "\n",
    "        processed_texts = []\n",
    "        total_pages = len(images)\n",
    "        page_number = 0\n",
    "\n",
    "        if image_processing_function:\n",
    "            texts = await image_processing_function(images, semaphore, file)\n",
    "            processed_texts.extend(texts)\n",
    "        else:\n",
    "            processed_texts.extend([''] * total_pages)\n",
    "\n",
    "        # Сreate a PDF from the collected texts\n",
    "        output_pdf_path = os.path.join(processed_dir, file.replace('.docx', '.pdf'))\n",
    "        save_texts_to_pdf(processed_texts, output_pdf_path)\n",
    "\n",
    "        # Delete temp PDF file\n",
    "        os.remove(pdf_temp_path)\n",
    "\n",
    "    async def extract_text_from_pdf(file, path_dir, processed_dir, image_processing_function=None, semaphore=None):\n",
    "        pdf_path = os.path.join(path_dir, file)\n",
    "        # Convert PDF pages to images\n",
    "        images = convert_from_path(pdf_path)\n",
    "\n",
    "        processed_texts = []\n",
    "        total_pages = len(images)\n",
    "        page_number = 0\n",
    "\n",
    "        if image_processing_function:\n",
    "            texts = await image_processing_function(images, semaphore, file)\n",
    "            processed_texts.extend(texts)\n",
    "        else:\n",
    "            processed_texts.extend([''] * total_pages)\n",
    "\n",
    "        # Сreate a PDF from the collected texts\n",
    "        output_pdf_path = os.path.join(processed_dir, file)\n",
    "        save_texts_to_pdf(processed_texts, output_pdf_path)\n",
    "\n",
    "    file_name = file.lower()\n",
    "    if file_name.endswith('.pdf'):\n",
    "        await extract_text_from_pdf(file, path_dir, processed_dir, image_processing_function, semaphore)\n",
    "    elif file_name.endswith('.docx'):\n",
    "        await extract_text_from_doc(file, path_dir, processed_dir, image_processing_function, semaphore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def preprocessing_document(path_dir, image_processing_function=image_processing_function):\n",
    "    path_files = [f for f in os.listdir(path_dir) if f.endswith(('.pdf', '.docx'))]\n",
    "    processed_dir = os.path.join(path_dir, 'processed')\n",
    "\n",
    "    # if not directory, create\n",
    "    if not os.path.exists(processed_dir):\n",
    "        os.makedirs(processed_dir)\n",
    "\n",
    "    total_files = len(path_files)  \n",
    "    processed_count = 0  \n",
    "\n",
    "    semaphore = asyncio.Semaphore(30)  \n",
    "\n",
    "    async def process_file(file):\n",
    "        nonlocal processed_count\n",
    "        await extract_image_from_file(file, path_dir, processed_dir, image_processing_function=image_processing_function, semaphore=semaphore)\n",
    "        processed_count += 1\n",
    "        logging.info(f\"Processing file: {file} ({processed_count}/{total_files})\")\n",
    "\n",
    "    tasks = [process_file(file) for file in path_files]\n",
    "\n",
    "    await asyncio.gather(*tasks)\n",
    "\n",
    "    logging.info(\"All complete all files from documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing definition folder\n",
    "def start_processing():\n",
    "    path_dir = \"./data/data_confluence\"\n",
    "    \n",
    "    asyncio.run(preprocessing_document(path_dir, image_processing_function=image_processing_function))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start_processing()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Chart 3. Объединение всех pdf по confluence в одну\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PyPDF2 import PdfMerger\n",
    "\n",
    "def merde_pdfs(path_folder, output_pdf_path):\n",
    "    pdf_files = [f for f in os.listdir(path_folder) if f.endswith(\".pdf\")]\n",
    "\n",
    "    pdf_files.sort()\n",
    "\n",
    "    merger = PdfMerger()\n",
    "\n",
    "    for pdf in pdf_files:\n",
    "        pdf_path = os.path.join(path_folder, pdf)\n",
    "        with open(pdf_path, \"rb\") as file:\n",
    "            merger.append(file)\n",
    "\n",
    "    with open(output_pdf_path, \"wb\") as file:\n",
    "        merger.write(file)\n",
    "    \n",
    "    merger.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    path_folder = \"./data/data_confluence/processed\"\n",
    "    output_pdf_path = \"./data/merge_pdf_confluence.pdf\"\n",
    "\n",
    "    merde_pdfs(path_folder, output_pdf_path)\n",
    "    print(f\"Merged pdfs and save in {output_pdf_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">**Extract information from Gitlab repository data**</font>\n",
    "\n",
    "После выполнения сбора информации с confluence требуется также загрузить в ассистента информацию из gitlab репозиториев проекта chat-ai. \n",
    "\n",
    "Для этого мы загрузим в промт ассистента в instructions полностью все данные из confluence в секции additional data для того, чтобы попробовать сформировать полную документацию для кода на основе архитектуру и прочих данных из confluence.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import asyncio\n",
    "from tqdm import tqdm\n",
    "from utils import OpenAIChatAssistant\n",
    "from dotenv import load_dotenv\n",
    "import json  \n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Maximum content size for sending (256000 characters)\n",
    "MAX_CONTENT_LENGTH = 256000\n",
    "\n",
    "# Function to process a single file\n",
    "async def process_file(idx, file_path, semaphore, assistant_id, total_files, output_file_path, lock, processed_files, state_file_path, max_retries=3):\n",
    "    async with semaphore:\n",
    "        # Check if the file has already been processed\n",
    "        if file_path in processed_files:\n",
    "            logger.info(f\"File already processed, skipping: {file_path}\")\n",
    "            return\n",
    "\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                logger.info(f\"Processing file {idx + 1}/{total_files}, attempt {attempt + 1}\")\n",
    "                assistant = OpenAIChatAssistant(assistant_id=assistant_id, api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "                await assistant.initialize()\n",
    "                # Reading the content of the file\n",
    "                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                    content = f.read()\n",
    "\n",
    "                # Checking the size of the content\n",
    "                if len(content) > MAX_CONTENT_LENGTH:\n",
    "                    logger.info(f\"File too large and will be skipped: {file_path}\")\n",
    "                    # Updating the list of processed files\n",
    "                    async with lock:\n",
    "                        processed_files.add(file_path)\n",
    "                        save_processed_files(processed_files, state_file_path)\n",
    "                    return\n",
    "\n",
    "                # Sending content to the assistant\n",
    "                response = await assistant.send_message(content)\n",
    "                # Writing the response to the output file\n",
    "                async with lock:\n",
    "                    with open(output_file_path, 'a', encoding='utf-8') as f_out:\n",
    "                        f_out.write(f\"File: {file_path}\\nResponse:\\n{response}\\n\\n\")\n",
    "                    # Updating the list of processed files\n",
    "                    processed_files.add(file_path)\n",
    "                    save_processed_files(processed_files, state_file_path)\n",
    "                return\n",
    "            except Exception as e:\n",
    "                # Check if the error is due to content being too large\n",
    "                if \"string_above_max_length\" in str(e):\n",
    "                    logger.info(f\"File too large and will be skipped: {file_path}\")\n",
    "                    # Updating the list of processed files\n",
    "                    async with lock:\n",
    "                        processed_files.add(file_path)\n",
    "                        save_processed_files(processed_files, state_file_path)\n",
    "                    return\n",
    "                else:\n",
    "                    logger.error(f\"Error processing file {file_path}, attempt {attempt + 1}: {e}\")\n",
    "                    await asyncio.sleep(2 ** attempt)\n",
    "        logger.error(f\"Failed to process file {file_path} after {max_retries} attempts.\")\n",
    "        # Updating the list of processed files\n",
    "        async with lock:\n",
    "            processed_files.add(file_path)\n",
    "            save_processed_files(processed_files, state_file_path)\n",
    "        return\n",
    "\n",
    "def load_processed_files(state_file_path):\n",
    "    if os.path.exists(state_file_path):\n",
    "        with open(state_file_path, 'r', encoding='utf-8') as f:\n",
    "            return set(json.load(f))\n",
    "    else:\n",
    "        return set()\n",
    "\n",
    "def save_processed_files(processed_files, state_file_path):\n",
    "    with open(state_file_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(list(processed_files), f)\n",
    "\n",
    "async def main():\n",
    "    assistant_id = os.getenv(\"OPENAI_ASST\")\n",
    "\n",
    "    if not assistant_id:\n",
    "        name = \"Coding assistant for chat-ai developer\"\n",
    "        text_for_instructions = \"Documentation from Confluence...\"\n",
    "        template = \"\"\"\n",
    "        <Context>\n",
    "        You are a developer assistant to help with development on the Chat-ai platform.\n",
    "        Your current task is to expand the documentation of already written modules, as well as to compile their descriptions.\n",
    "        At the same time, you must fully save the input code and return a response consisting of the source code and detailed documentation with comments.\n",
    "        Temperature = 0.1\n",
    "\n",
    "        <Additional information>\n",
    "\n",
    "        Below is the documentation from confluence, it will allow you to more fully do the documentation and description of the module.\n",
    "\n",
    "        {text_for_instructions}\n",
    "\n",
    "        <Final instructions>\n",
    "        Your current task is to expand the documentation of already written modules, as well as to compile their descriptions.\n",
    "        At the same time, you must fully save the input code and return a response consisting of the source code and detailed documentation with comments.\n",
    "        \"\"\"\n",
    "        prompt = template.format(text_for_instructions=text_for_instructions)\n",
    "\n",
    "        # Creating the assistant\n",
    "        assistant = OpenAIChatAssistant(assistant_id=None, api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "        assistant.create_assistant(\n",
    "            name=name,\n",
    "            instructions=prompt,\n",
    "            tools=[\n",
    "                {\"type\": \"code_interpreter\"},\n",
    "                {\"type\": \"file_search\"}\n",
    "            ],\n",
    "            model=\"gpt-4o-mini\"\n",
    "        )\n",
    "        assistant_id = assistant.assistant_id\n",
    "        model = assistant.model\n",
    "        logger.info(f\"Id Assistant: {assistant_id}\")\n",
    "        os.environ[\"OPENAI_ASST\"] = assistant_id\n",
    "        logger.info(f\"Model: {model}\")\n",
    "    else:\n",
    "        logger.info(f\"Using existing Assistant ID: {assistant_id}\")\n",
    "\n",
    "    # Path to the directory with repositories\n",
    "    data_gitlab_path = \"./data/data_gitlab\"\n",
    "    output_data_path = \"./data\"\n",
    "\n",
    "    # Path to the state file\n",
    "    state_file_path = os.path.join(output_data_path, \"processed_files.json\")\n",
    "\n",
    "    # Loading the list of processed files\n",
    "    processed_files = load_processed_files(state_file_path)\n",
    "\n",
    "    batch_size = 50  # Batch size\n",
    "\n",
    "    # Getting the list of repositories\n",
    "    repos = [d for d in os.listdir(data_gitlab_path) if os.path.isdir(os.path.join(data_gitlab_path, d))]\n",
    "\n",
    "    for repo in repos:\n",
    "        repo_path = os.path.join(data_gitlab_path, repo)\n",
    "        logger.info(f\"Processing repository: {repo}\")\n",
    "\n",
    "        # Collecting all files in the repository\n",
    "        file_paths = []\n",
    "        for root, dirs, files in os.walk(repo_path):\n",
    "            for file in files:\n",
    "                file_paths.append(os.path.join(root, file))\n",
    "\n",
    "        total_files = len(file_paths)\n",
    "\n",
    "        # Path to the output file\n",
    "        output_file_path = os.path.join(output_data_path, f\"{repo}.txt\")\n",
    "\n",
    "        # Lock for writing to file and updating state\n",
    "        lock = asyncio.Lock()\n",
    "\n",
    "        # Processing files in batches\n",
    "        for batch_start in range(0, total_files, batch_size):\n",
    "            batch_end = min(batch_start + batch_size, total_files)\n",
    "            batch_file_paths = file_paths[batch_start:batch_end]\n",
    "            logger.info(f\"Starting processing batch of files from {batch_start + 1} to {batch_end}\")\n",
    "\n",
    "            max_concurrent_tasks = 5  \n",
    "            semaphore = asyncio.Semaphore(max_concurrent_tasks)\n",
    "            tasks = []\n",
    "\n",
    "            for idx_in_batch, file_path in enumerate(batch_file_paths):\n",
    "                idx = batch_start + idx_in_batch\n",
    "                task = asyncio.create_task(process_file(idx, file_path, semaphore, assistant_id, total_files, output_file_path, lock, processed_files, state_file_path))\n",
    "                tasks.append(task)\n",
    "\n",
    "            # Creating a progress bar\n",
    "            with tqdm(total=len(tasks), desc=f\"Processing batch of files in {repo}\", unit=\"file\") as pbar:\n",
    "                for future in asyncio.as_completed(tasks):\n",
    "                    await future\n",
    "                    pbar.update(1)\n",
    "\n",
    "            logger.info(f\"Finished processing batch of files from {batch_start + 1} to {batch_end}\")\n",
    "\n",
    "            await asyncio.sleep(10)  \n",
    "\n",
    "        logger.info(f\"Finished processing repository: {repo}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
